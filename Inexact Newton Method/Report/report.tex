\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{textcomp}
\usepackage{a4wide}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{subfig}
\usepackage{listings}
\usepackage{hyperref}
%\usepackage{fontspec}
\usepackage{pgfplots}
\usepackage{tikz}

\lstset{
language=Python,
basicstyle=\ttfamily\small,
otherkeywords={self},                   
}

\title{Title}
\title{Неточный метод Ньютона.}
\date{4 октября 2015}
\author{Павел Измаилов}

\begin{document}

\renewcommand{\contentsname}{\centerline{\bf Содержание}} %!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

\renewcommand{\refname}{\centerline{\bf Список литературы}}

\newlength{\arrayrulewidthOriginal}
\newcommand{\Cline}[2]{%
  \noalign{\global\setlength{\arrayrulewidthOriginal}{\arrayrulewidth}}%
  \noalign{\global\setlength{\arrayrulewidth}{#1}}\cline{#2}%
  \noalign{\global\setlength{\arrayrulewidth}{\arrayrulewidthOriginal}}}


\def\vec#1{\mathchoice{\mbox{\boldmath$\displaystyle#1$}}{\mbox{\boldmath$\textstyle#1$}} {\mbox{\boldmath$\scriptstyle#1$}} {\mbox{\boldmath$\scriptscriptstyle#1$}}}

%\maketitle
\centerline{Московский государственный университет им. М. В. Ломоносова}

\centerline{Факультет вычислительной математики и кибернетики}

\vspace{5 cm}

\centerline{\Large Отчет по заданию}

\vspace{1 cm}

\centerline{\Large \bf Неточный метод Ньютона}
\centerline{\Large \bf для $\ell_2$-регуляризованной логистической регрессии}

\vspace{6 cm}

\begin{flushright} 
Выполнил студент 317 группы

Измаилов Павел Алексеевич
\end{flushright}

\vfill 

\centerline{Москва,  5 ноября 2015}
\thispagestyle{empty} 
\pagebreak

\section{Описание проделанной работы}

\hspace{0.6cm}В данном отчете содержатся результаты экспериментов, проведенных мной в соответствии с первым заданием по спецкурсу <<методы оптимизации в машинном обучении>>. Мной были реализованы метод Ньютона, неточный метод Ньютона, а также метод сопряженных градиентов для решения задачи квадратичного программирования. Также было проведено сравнение точного и неточного методов Ньютона, а также сравнение неточного метода с нелинейным методом сопряженных градиентов и с методом L-BFGS из библиотеки \lstinline{scipy.optimize}.

\section{Рассматриваемая задача}

\hspace{0.6cm}В данной работе сравниваются результаты работы различных методов оптимизации на задаче логистической регрессии. Целевая функция этой задачи имеет вид
$$ F(\vec w) = \sum\limits_{i = 1}^{N} \ln(1 + \exp(-y_i \vec w^T \vec x)) + \frac \lambda 2 ||\vec w||_2^2.$$
Здесь $\vec w \in \mathbb{R}^D$, $\vec x \in \mathbb{R}^{N \times D}$ — объекты обучающей выборки, $\vec y \in \{-1, 1\}^N$ — ответы на обучающей выборке, $\lambda \in \mathbb{R}$ — константа регуляризации.

\section{Рассматриваемые методы}

\hspace{0.6cm}В данном разделе приводятся краткие описания методов оптимизации, рассматриваемых в данной работе.

	\subsection{Правило Вольфа}
	
		В данной работе как для точного, так и для неточного метода Ньютона для выбора параметра длины шага использовалось правило Вольфа, которое имеет следующий вид. Фиксируем $\varepsilon_1, \varepsilon_2 \in (0, 1)$, $\chi_1 > 1$, $\chi_2 \in (0, 1)$. Полагаем $\check\alpha = \hat\alpha = 0$, $\alpha = \alpha_{k}$. 
		\begin{enumerate}
			\item Проверяем выполнение неравенств
			$$F(\vec w_k + \alpha \vec d_k) \le F(\vec{w_k}) + \varepsilon_1\alpha \langle \nabla F(\vec w_k), d_k \rangle$$
			$$\langle \nabla F(\vec w_k + \alpha \vec d_k), \vec d_k \rangle \ge \varepsilon_2  \langle \nabla F(\vec w_k), \vec d_k \rangle,$$
			где $\langle \vec{a}, \vec{b} \rangle$ означает скалярное произведение векторов $\vec{a}$ и $\vec{b}$.
			
			Если оба они выполнены, то переходим к пункту 6.
			
			\item Если нарушено первое неравенство, то $\hat\alpha = \alpha$.
			
			\item Если нарушено второе неравенство, то $\check\alpha = \alpha$.
			
			\item Если $\hat \alpha = 0$, то выбираем новое значение $\alpha = \check\alpha \chi_1$ и переходим к пункту 1.
			
			\item Выбираем новое значение $\alpha = \hat\alpha \chi_2 + \check\alpha(1 - \chi_2)$ и переходим к пункту 1.
			
			\item Полагаем $\alpha_{k+1} = \alpha$.
			
		\end{enumerate} 
		
		Во всех экспериментах параметры полагались равными $\varepsilon_1 = 10^{-4}, \varepsilon_2 = 0.9, \chi_1 = \chi_2 = 0.5$.
		
		\subsection{Метод Ньютона}
		
		\hspace{0.6cm} Итерация метода Ньютона имеет вид 
		$$ \vec w_{k+1} = \vec w_k - \alpha_k \nabla^2 F(\vec w_k)^{-1}\cdot \nabla F(\vec w_k),$$
		где $\nabla^2 F(\vec w)$ и $\nabla F(\vec w)$ — соответственно гессиан и градиент функции $F$ в точке $w$, а $\alpha_k$ — параметр длины шага, выбираемый тем или иным образом. В данной работе для выбора параметра длины шага использовалось правило Вольфа.	
	
	\subsection{Метод сопряженных градиентов}
	
		\hspace{0.6cm}Метод сопряженных градиентов предназначен для решения задачи оптимизации
		$$f(x) = \frac 1 2 \langle A x, x \rangle  - \langle b, x\rangle \rightarrow \min\limits_{x},$$
		с симметричной положительно определенной матрицей  $A \in \mathbb{R}^{n \times n}$. Эта задача эквивалентна линейной системе $Ax = b$. Для решения этой задачи в методе сопряженных градиентов строится система векторов $d_i, i = 1 \ldots n$, такая что $\langle A d_i, d_j \rangle = 0 \hspace{0.2cm} \forall i \ne j$. Такая система называется сопряженной относительно матрицы $A$. Будем обозначать через $x_k$ приближение, полученные методом сопряженных градиентов на $k$-ой итерации $g_k = \nabla f(x_k) = A x_k - b$, $f_k = f(x_k)$. Система $d_k$ строится в методе сопряженных градиентов следующим образом: 
		\begin{enumerate}
			\item Полагается $g_0 = Ax_0 - b$, $d_0 = -g_0$, $u_0 = A d_0$.
			\item Для $k = 1 \ldots \#iter$ полагается
			\begin{enumerate}
				\item $\alpha_k = \cfrac{g_k^T g_k} {d_k^T u_k}$;
				\item $x_{k + 1} = x_k + \alpha_k d_k$;
				\item $g_{k+1} = g_k + \alpha_k u_k$;
				\item Если $|| g_{k+1}|| < \varepsilon$,  где $\varepsilon$ — требуемая точность, остановиться;
				\item  $\beta_{k} = \cfrac{g_{k+1}^T g_{k+1}} {g_k^T g_k}$;
				\item $d_{k+1} = -g_{k+1} + \beta_{k}d_{k}$;
				\item $u_{k+1} = A d_k+1$.
			\end{enumerate}
		\end{enumerate}
		Если все операции метода осуществлять точно, то решение задачи будет получено не более, чем за $n$ итераций.
	
	\subsection{Неточный метод Ньютона}
	\hspace{0.6cm} Итерации неточного метода Ньютона имеют вид
	$$ \vec w_{k+1} = \vec w_k + \alpha_k d_k,$$
	где $d_k$ — направление убывания, получаемое приближенным решением системы уравнений $\nabla^2 F(\vec w_k) d_k = -\nabla F(\vec w_k)$ с помощью метода сопряженных градиентов. При этом точность, с которой решается эта система на $k$-ой итерации, в данной работе полагается равной $\varepsilon_k = \min\{ 0.5, \sqrt{|| \nabla F(\vec w_k)||}\}$.


\section{Эксперименты}

\hspace{0.6cm}В данном разделе приводятся результаты проведенных экспериментов. Для получения графиков все методы запускались на некоторое фиксированное количество итераций, а в качестве минимального значения функции $f_*$ бралось приближение, полученное заранее запуском одного из методов на большое количество итераций.

	\subsection{Метод Ньютона}
	
	\hspace{0.6cm}В данной секции приводятся результаты работы метода Ньютона на небольшой задаче логистичекой регрессии. На графиках на рисунке \ref{newton} показаны результаты работы метода Ньютона на задаче со модельными данными и на задаче с реальными данными из набора fourclass.
	
\begin{figure}[!h]
	\centering
	\subfloat{
		\scalebox{0.9}{
			\input{../Plots/newton_5_1000.tikz}
		}
	}
	\subfloat{
		%\mbox{
		\scalebox{0.9}{
                		\input{../Plots/newton_Fourclass.tikz}
		}
		%}
	}
	\caption{Метод Ньютона на небольшой задаче логистической регрессии.}
	\label{newton}
\end{figure}

	Из графиков видно, что сходимость носит сверхлинейный характер. На наборе данных fourclass норма градиента становится меньше машинной точности уже на пятой итерации.
	
	\pagebreak
	\subsection{Метод сопряженных градиентов}
	
	\hspace{0.6cm}В данном разделе приводятся результаты работы метода сопряженных градиентов.
	Для генерации симметричной положительно определенной матрицы с заданным набором собственных значений использовалась процедура, предложенная в задании, с учетом того, что у положительно определенной матрицы собственные значения совпадают с сингулярными.  
	
	
	\begin{figure}[!h]
	\centering
	\subfloat{
		\scalebox{1.2}{
			\input{../Plots/cg_100_50.tikz}
		}
	}
	\caption{Метод сопряженных градиентов для квадртаичной задачи с матрицей \newline $A \in \mathbb{R}^{100 \times 100}$ для 50 и 10 кластеров собственных значений.}
	\label{cg}
\end{figure}
	На рисунке \ref{cg} представлен график сходимости метода сопряженных градиентов по итерациям для двух различных задач квадратичного программирования размерности $100$. В первой из них собственные значения матрицы разбиваются на 50 кластеров, а во второй — на 10. Видно, что метод сходится за число итераций примерно равное числу кластеров собственных значений. 
	

	\subsection{Неточный метод Ньютона}
	
	\hspace{0.6cm} В данном разделе представлены результаты работы неточного метода Ньютона, а также его сравнение с другими методами. 
	
	
\begin{figure}[!h]
	\centering
	\subfloat{
		\scalebox{0.9}{
			\input{../Plots/inexact_newton_5_1000.tikz}
		}
	}
	\subfloat{
		%\mbox{
		\scalebox{0.9}{
                		\input{../Plots/inexact_newton_Fourclass.tikz}
		}
		%}
	}
	\caption{Точный и неточный методы Ньютона на небольшой задаче логистической регрессии.}
	\label{hfn}
\end{figure}
	
	На рисунке \ref{hfn} показана зависимость логарифма невязки по функции от времени для обычного и неточного методов Ньютона на сгенерированных данных и на данных fourclass. Видно, что точный метод Ньютона на этих задачах работает несколько лучше, хотя оба метода сходятся очень быстро. 
	
	Далее рассмотрим результаты работы метода на больших задачах и сравним его с L-BFGS и с нелинейным методом сопряженных градиентов. 
	
	\subsection{Наборы данных leukemia и duke breast cancer}
	
		Набор данных leukemia состоит из $N = 38$ объектов, имеющих $D = 7129$ признаков. Для экспериментов с этим набором данных использовалась плотная матрица объектов. Набор данных duke breast cancer состоит из $N = 44$ объектов, обладающих $D = 7129$ признаками. Для эксперименотов с этим набором использовалась разреженная матрица объектов. Результаты работы методов приведены на рисунке \ref{deseases}.
	
	
		\begin{figure}[!h]
			\centering
			\subfloat{
				\scalebox{0.9}{
					\input{../Plots/inexact_newton_leukemia.tikz}
				}
			}
			\subfloat{
				%\mbox{
				\scalebox{0.9}{
		                		\input{../Plots/inexact_newton_Duke_breast-cancersparse_.tikz}
				}
				%}
			}
			\caption{Наборы данных leukemia ($N = 38$, $D = 7129$) и duke breast-cancer ($N = 44$, $D = 7129$).}
			\label{deseases}
		\end{figure}
	
	В обоих случаях все методы сошлись очень быстро. Разницу в результатах можно объяснить тем, что расположение начальной точки по отношению к оптимуму в этих двух экспериментах было разным.
	
	\subsubsection{Набор данных gisette}
	
		Набор данных gisette состоит из $N = 6000$ объектов, число признаков которых равно $D  = 5000$. В этом эксперименте использовалась плотная матрица объектов. На рисунке \ref{Gisette} представлены графики сходимости методов. 
		
		\begin{figure}[!h]
			\centering
			\subfloat{
				\scalebox{1.2}{
					\input{../Plots/inexact_newton_Gisette.tikz}
				}
			}
			\caption{Набор данных gisette, $N = 6000$, $D = 5000$.}
			\label{Gisette}
		\end{figure}
	
		Из графиков видно, что итерации неточного метода Ньютона на этой задаче занимают значительно больше времени, чем итерации других методов. Тем не менее, эти итерации значительно эффективнее и метод очень быстро достигает очень низкой нормы градиента и останавливается, обогнав остальные методы. Метод CG на данной задаче существенно уступает двум другим методам. 
	
	\subsubsection{Набор данных Real-sim}
	
		Набор данных real-sim состоит из $N = 72309$ объектов, обладающих $D = 20958$ признаками. Однако для экспериментов были использованы только первые 10000 объектов, так как иначе методы работали слишком долго. В этом эксперименте использовалась разреженная матрица объектов. Результаты работы методов приведены на рисунке \ref{real-sim}.
		
		\begin{figure}[!h]
			\centering
			\subfloat{
				\scalebox{1.2}{
					\input{../Plots/inexact_newton_Real-simsparse_.tikz}
				}
			}
			\caption{Набор данных real-sim, $N = 72309$, $D = 20958$.}
			\label{real-sim}
		\end{figure}
		
		На этой задаче методы L-BFGS и неточный метод Ньютона показали близкие результаты. Метод CG снова проиграл двум другим методам.	

\pagebreak	
\section{Выводы}
	
	\hspace{0.5cm} По результатам экспериментов можно сделать ряд выводов. 
	
	Во-первых, на небольших задачах (когда гессиан вычисляется быстро) метод Ньютона ожидаемо сходится несколько быстрее неточного метода Ньютона и поэтому в таких задачах имеет смысл использовать точный метод. 
	
	Во-вторых экспериментально было проверено утверждение о том, что метод сопряженных градиентов для квадратичной задачи $\langle A x, x \rangle + \langle b, x \rangle \rightarrow \min\limits_x$ сходится за число итераций примерно равное числу кластеров собственных значений матрицы $A$.
	
	
	В-третьих было проведено сравнение неточного метода Ньютона с методами CG и L-BFGS из библиотеки \lstinline{scipy.optimize} на задачах в пространствах размерности \newline $D \ge 5000$. Как и следовало ожидать, неточный метод Ньютона обладает лучшей скоростью сходимости по итерациям, однако сами его итерации существенно дольше, чем у других двух методов. На наборах данных leukemia и duke breast-cancer методы показали близкие результаты. Эти задачи можно отнести к небольшим, все три метода сходятся на них быстро, и пользоваться можно любым. На больших наборах данных наборах данных gisette и real-sim методы L-BFGS-B и неточный метод Ньютона показали близкие результаты. При этом на ранних итерациях на наборе данных gisette метод L-BFGS-B показывает лучшую точность, поэтому на больших задачах, если достаточна не слишком высокая точность, следует отдавать преимущество ему. Метод CG в экспериментах на этих двух наборах данных показал себя существенно хуже других двух методов.
	
\end{document}